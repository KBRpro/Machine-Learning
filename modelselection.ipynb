{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cópia de KNNfuncional.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ezGavuimOeh"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSu5TLlVCql-",
        "outputId": "c496cdf8-02a9-4cf6-9434-e5cef9b23570"
      },
      "source": [
        "def load_data(): #ler dados em função\n",
        "    return pd.read_csv('data.csv') #ler database\n",
        "df = load_data() #definir uma variavel\n",
        "df.pop('id') #retira a coluna id pq n tem necessidade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        842302\n",
              "1        842517\n",
              "2      84300903\n",
              "3      84348301\n",
              "4      84358402\n",
              "         ...   \n",
              "564      926424\n",
              "565      926682\n",
              "566      926954\n",
              "567      927241\n",
              "568       92751\n",
              "Name: id, Length: 569, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "htP0HMWECtDU",
        "outputId": "ae3bc4b0-f3ac-4778-8891-6c92351b23b9"
      },
      "source": [
        "mapping_dict={'M':1,\n",
        "              'B':0}\n",
        "df['diagnosis']=df['diagnosis'].map(mapping_dict) #trata o diagnostico como valores binarios\n",
        "df #troca os valores de malefico e benefico para 0 e 1 para melhor tratamento"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>1</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>1</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>1</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>1</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>0</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     diagnosis  radius_mean  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0            1        17.99  ...                  0.11890          NaN\n",
              "1            1        20.57  ...                  0.08902          NaN\n",
              "2            1        19.69  ...                  0.08758          NaN\n",
              "3            1        11.42  ...                  0.17300          NaN\n",
              "4            1        20.29  ...                  0.07678          NaN\n",
              "..         ...          ...  ...                      ...          ...\n",
              "564          1        21.56  ...                  0.07115          NaN\n",
              "565          1        20.13  ...                  0.06637          NaN\n",
              "566          1        16.60  ...                  0.07820          NaN\n",
              "567          1        20.60  ...                  0.12400          NaN\n",
              "568          0         7.76  ...                  0.07039          NaN\n",
              "\n",
              "[569 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F-sz8QzbmUX"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "\n",
        "X = df.iloc[:,1:31].values\n",
        "y = df.iloc[:,0:1].values "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT93rKF3DUEx"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=1, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ob6UFMjbpLK"
      },
      "source": [
        "pipe = Pipeline([\n",
        "        ('z-score', StandardScaler()),\n",
        "        ('reduce_dim', PCA(n_components=3)),\n",
        "        ('classify', KNeighborsClassifier(n_neighbors=1))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyaOwJB4N3-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8641900a-ebbe-48dc-e470-a34fd68b9769"
      },
      "source": [
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('z-score',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('reduce_dim',\n",
              "                 PCA(copy=True, iterated_power='auto', n_components=3,\n",
              "                     random_state=None, svd_solver='auto', tol=0.0,\n",
              "                     whiten=False)),\n",
              "                ('classify',\n",
              "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
              "                                      metric='minkowski', metric_params=None,\n",
              "                                      n_jobs=None, n_neighbors=1, p=2,\n",
              "                                      weights='uniform'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzLLtpGAOTyo",
        "outputId": "e6d221a0-74a7-44c2-b3d4-6e7b22fcc496"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_train_pred = pipe.predict(X_train)\n",
        "accuracy_score(y_train, y_train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZET3S7-jPgWn",
        "outputId": "d59875b7-cc9f-4bb4-a3e2-64c3599f548f"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_test_pred = pipe.predict(X_test)\n",
        "accuracy_score(y_test, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9385964912280702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it6LPPvIQ_1U"
      },
      "source": [
        "param_grid = {\n",
        "    'reduce_dim__n_components': [1, 2, 3, 4],\n",
        "    'classify__n_neighbors': [2, 3, 4, 5]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipe, cv=2, n_jobs=1, param_grid=param_grid, scoring='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSkOVzwaTpWj",
        "outputId": "edd8e25e-73fc-4cc3-cfdf-cfe3f9b065ba"
      },
      "source": [
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('z-score',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('reduce_dim',\n",
              "                                        PCA(copy=True, iterated_power='auto',\n",
              "                                            n_components=3, random_state=None,\n",
              "                                            svd_solver='auto', tol=0.0,\n",
              "                                            whiten=False)),\n",
              "                                       ('classify',\n",
              "                                        KNeighborsClassifier(algorithm='auto',\n",
              "                                                             leaf_size=30,\n",
              "                                                             metric='minkowski',\n",
              "                                                             metric_params=None,\n",
              "                                                             n_jobs=None,\n",
              "                                                             n_neighbors=1, p=2,\n",
              "                                                             weights='uniform'))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=1,\n",
              "             param_grid={'classify__n_neighbors': [2, 3, 4, 5],\n",
              "                         'reduce_dim__n_components': [1, 2, 3, 4]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1hGNhmXCKmS",
        "outputId": "f55f2d87-3601-4dd9-fd98-b9f79b156410"
      },
      "source": [
        "print(grid.cv_results_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'mean_fit_time': array([0.00393772, 0.00212908, 0.00217164, 0.00215876, 0.00213373,\n",
            "       0.00209463, 0.00215721, 0.00213754, 0.00216687, 0.00292885,\n",
            "       0.0021714 , 0.00261164, 0.00223815, 0.00235212, 0.00233543,\n",
            "       0.00230277]), 'std_fit_time': array([1.76715851e-03, 3.09944153e-06, 4.18424606e-05, 5.28097153e-05,\n",
            "       1.13248825e-05, 1.10864639e-05, 4.76837158e-06, 5.84125519e-06,\n",
            "       1.20401382e-05, 7.08222389e-04, 2.30073929e-05, 3.37600708e-04,\n",
            "       1.10864639e-05, 1.84774399e-05, 1.46627426e-05, 7.03334808e-06]), 'mean_score_time': array([0.00802207, 0.00753236, 0.00764644, 0.00739861, 0.00725293,\n",
            "       0.00733364, 0.00742686, 0.00752532, 0.00734162, 0.00850701,\n",
            "       0.01010621, 0.00861418, 0.00832319, 0.00774646, 0.00787389,\n",
            "       0.00795484]), 'std_score_time': array([6.31332397e-04, 2.09093094e-04, 3.89814377e-05, 3.79085541e-05,\n",
            "       2.67028809e-05, 1.37090683e-05, 3.06367874e-05, 4.11272049e-05,\n",
            "       4.64916229e-05, 9.97781754e-04, 2.26509571e-03, 1.46269798e-04,\n",
            "       7.77244568e-05, 2.14576721e-06, 5.54323196e-05, 4.26769257e-05]), 'param_classify__n_neighbors': masked_array(data=[2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_reduce_dim__n_components': masked_array(data=[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False, False, False, False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'classify__n_neighbors': 2, 'reduce_dim__n_components': 1}, {'classify__n_neighbors': 2, 'reduce_dim__n_components': 2}, {'classify__n_neighbors': 2, 'reduce_dim__n_components': 3}, {'classify__n_neighbors': 2, 'reduce_dim__n_components': 4}, {'classify__n_neighbors': 3, 'reduce_dim__n_components': 1}, {'classify__n_neighbors': 3, 'reduce_dim__n_components': 2}, {'classify__n_neighbors': 3, 'reduce_dim__n_components': 3}, {'classify__n_neighbors': 3, 'reduce_dim__n_components': 4}, {'classify__n_neighbors': 4, 'reduce_dim__n_components': 1}, {'classify__n_neighbors': 4, 'reduce_dim__n_components': 2}, {'classify__n_neighbors': 4, 'reduce_dim__n_components': 3}, {'classify__n_neighbors': 4, 'reduce_dim__n_components': 4}, {'classify__n_neighbors': 5, 'reduce_dim__n_components': 1}, {'classify__n_neighbors': 5, 'reduce_dim__n_components': 2}, {'classify__n_neighbors': 5, 'reduce_dim__n_components': 3}, {'classify__n_neighbors': 5, 'reduce_dim__n_components': 4}], 'split0_test_score': array([0.85087719, 0.89473684, 0.9254386 , 0.92982456, 0.87280702,\n",
            "       0.91666667, 0.92105263, 0.9254386 , 0.87719298, 0.9122807 ,\n",
            "       0.9254386 , 0.9254386 , 0.87719298, 0.9122807 , 0.9254386 ,\n",
            "       0.92982456]), 'split1_test_score': array([0.85462555, 0.89867841, 0.9339207 , 0.92951542, 0.89427313,\n",
            "       0.91629956, 0.95594714, 0.96035242, 0.88546256, 0.92070485,\n",
            "       0.95594714, 0.95594714, 0.89867841, 0.9339207 , 0.969163  ,\n",
            "       0.97356828]), 'mean_test_score': array([0.85275137, 0.89670763, 0.92967965, 0.92966999, 0.88354007,\n",
            "       0.91648311, 0.93849988, 0.94289551, 0.88132777, 0.91649277,\n",
            "       0.94069287, 0.94069287, 0.8879357 , 0.9231007 , 0.9473008 ,\n",
            "       0.95169642]), 'std_test_score': array([0.00187418, 0.00197079, 0.00424105, 0.00015457, 0.01073306,\n",
            "       0.00018355, 0.01744725, 0.01745691, 0.00413479, 0.00421207,\n",
            "       0.01525427, 0.01525427, 0.01074272, 0.01082   , 0.0218622 ,\n",
            "       0.02187186]), 'rank_test_score': array([16, 12,  7,  8, 14, 11,  6,  3, 15, 10,  4,  4, 13,  9,  2,  1],\n",
            "      dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbW-CzdrCOVu",
        "outputId": "467f2736-5faf-44f8-8ccf-a6006ae50435"
      },
      "source": [
        "grid.cv_results_['mean_test_score']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.85275137, 0.89670763, 0.92967965, 0.92966999, 0.88354007,\n",
              "       0.91648311, 0.93849988, 0.94289551, 0.88132777, 0.91649277,\n",
              "       0.94069287, 0.94069287, 0.8879357 , 0.9231007 , 0.9473008 ,\n",
              "       0.95169642])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy_xMkpYCPv9",
        "outputId": "bca93eeb-c188-441d-b091-721b9881f466"
      },
      "source": [
        "print(grid.best_score_)\n",
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9516964216709174\n",
            "{'classify__n_neighbors': 5, 'reduce_dim__n_components': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtQNulgPCR0g"
      },
      "source": [
        "clf = grid.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt-rFb68CTkE",
        "outputId": "ae271cbd-9b02-425c-e711-a57d429c8f97"
      },
      "source": [
        "y_test_pred = clf.predict(X_test)\n",
        "accuracy_score(y_test, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.956140350877193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}